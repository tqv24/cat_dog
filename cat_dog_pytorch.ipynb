{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been successfully moved to their respective directories.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create directories for categories\n",
    "os.makedirs('train/cat', exist_ok=True)\n",
    "os.makedirs('train/dog', exist_ok=True)\n",
    "\n",
    "# Directory where the images are initially stored\n",
    "source_dir = 'train'\n",
    "\n",
    "# Process each file in the source directory\n",
    "for filename in os.listdir(source_dir):\n",
    "    if filename.endswith(('.jpg', '.jpeg', '.png')):  # Check for image files\n",
    "        if filename.startswith('cat'):\n",
    "            category = 'cat'\n",
    "        else:\n",
    "            category = 'dog'\n",
    "        \n",
    "        # Source file path\n",
    "        source_path = os.path.join(source_dir, filename)\n",
    "        \n",
    "        # Destination file path\n",
    "        destination_path = os.path.join(source_dir, category, filename)\n",
    "        \n",
    "        # Move the file to the appropriate category directory\n",
    "        shutil.move(source_path, destination_path)\n",
    "\n",
    "print(\"Files have been successfully moved to their respective directories.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dir = 'train'\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128,128))\n",
    "])\n",
    "train_dataset = ImageFolder(root = train_dir,\n",
    "                            transform = transform)\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              shuffle = True,\n",
    "                              batch_size = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.4183e-02, 1.0403e-02, 1.0333e-02,  ..., 7.8985e-01,\n",
      "           9.0956e-01, 9.1440e-01],\n",
      "          [1.1037e-02, 1.1341e-02, 7.8113e-03,  ..., 8.2377e-01,\n",
      "           9.1702e-01, 9.1517e-01],\n",
      "          [1.4810e-02, 7.3012e-03, 6.8339e-03,  ..., 8.7358e-01,\n",
      "           9.2442e-01, 9.2425e-01],\n",
      "          ...,\n",
      "          [6.3807e-01, 6.4623e-01, 6.6264e-01,  ..., 2.2673e-01,\n",
      "           2.3473e-01, 2.2335e-01],\n",
      "          [6.4038e-01, 6.5977e-01, 6.4710e-01,  ..., 2.1819e-01,\n",
      "           2.2576e-01, 2.2538e-01],\n",
      "          [6.4367e-01, 6.6422e-01, 6.5157e-01,  ..., 2.3738e-01,\n",
      "           2.2634e-01, 2.2472e-01]],\n",
      "\n",
      "         [[6.6405e-03, 3.3806e-03, 2.9737e-03,  ..., 7.5566e-01,\n",
      "           8.8069e-01, 8.7204e-01],\n",
      "          [3.9130e-03, 4.2027e-03, 1.5302e-03,  ..., 7.7956e-01,\n",
      "           8.8302e-01, 8.8186e-01],\n",
      "          [7.0527e-03, 1.0767e-03, 8.6437e-06,  ..., 8.1955e-01,\n",
      "           8.8416e-01, 8.9660e-01],\n",
      "          ...,\n",
      "          [6.4199e-01, 6.5015e-01, 6.6656e-01,  ..., 2.2049e-01,\n",
      "           1.9914e-01, 1.7491e-01],\n",
      "          [6.4175e-01, 6.6186e-01, 6.5062e-01,  ..., 2.0738e-01,\n",
      "           1.8524e-01, 1.7109e-01],\n",
      "          [6.1647e-01, 6.4954e-01, 6.5036e-01,  ..., 2.0009e-01,\n",
      "           1.8207e-01, 1.6800e-01]],\n",
      "\n",
      "         [[1.0262e-02, 6.4813e-03, 6.4111e-03,  ..., 4.7215e-01,\n",
      "           6.0761e-01, 5.8882e-01],\n",
      "          [7.1157e-03, 7.4198e-03, 3.8897e-03,  ..., 5.1201e-01,\n",
      "           6.2084e-01, 5.8549e-01],\n",
      "          [1.0888e-02, 3.3797e-03, 2.9123e-03,  ..., 5.4545e-01,\n",
      "           6.1839e-01, 6.0266e-01],\n",
      "          ...,\n",
      "          [4.7728e-01, 4.8544e-01, 5.0186e-01,  ..., 1.5733e-01,\n",
      "           1.4082e-01, 1.3750e-01],\n",
      "          [4.7797e-01, 4.9750e-01, 4.8609e-01,  ..., 1.5620e-01,\n",
      "           1.4863e-01, 1.3714e-01],\n",
      "          [4.6373e-01, 4.8398e-01, 4.8682e-01,  ..., 1.3705e-01,\n",
      "           1.3067e-01, 1.1573e-01]]]]) torch.Size([1, 3, 128, 128])\n",
      "tensor([0]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "img_batch, label_batch  = next(iter(train_dataloader))\n",
    "print(img_batch, img_batch.shape)\n",
    "print(label_batch, label_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3,32, kernel_size = 3, padding = 1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            nn.Conv2d(32, 64, kernel_size = 3, padding = 1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.classifier = nn.Linear(64*32*32, 1)\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "net = Net()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.001)\n",
    "\n",
    "for epoch in range(1):\n",
    "    for features, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(features)\n",
    "        loss = criterion(outputs, labels.view(-1,1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'torchmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4033]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "image = Image.open('cat.1.jpg')\n",
    "image_tensor = transform(image)\n",
    "image_re = image_tensor.unsqueeze(0)\n",
    "out = net(image_re)\n",
    "prob = torch.sigmoid(out)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3,32, kernel_size = 3, padding = 1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            nn.Conv2d(32, 64, kernel_size = 3, padding = 1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.classifier = nn.Linear(64*32*32, 1)\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('model_torch.pth'))\n",
    "\n",
    "model\n",
    "import os\n",
    "folder_path = \"test\"\n",
    "image_paths = []\n",
    "for image_name in os.listdir(folder_path):\n",
    "    image_path = os.path.join(folder_path, image_name)\n",
    "    image_paths.append(image_path)\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "\n",
    "vgg = vgg16(weights = VGG16_Weights.DEFAULT)\n",
    "backbone = nn.Sequential(\n",
    "    *list(vgg.features.children())\n",
    ")\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class BinaryCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryCNN, self).__init__()\n",
    "        self.backbone = nn.Sequential(*list(vgg.features.children()))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(25088, 2000),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(2000,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "BinaryCNN()\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dir = 'train'\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224,224))\n",
    "])\n",
    "train_dataset = ImageFolder(root = train_dir,\n",
    "                            transform = transform)\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              shuffle = True,\n",
    "                              batch_size = 1)\n",
    "\n",
    "img,_ = next(iter(train_dataloader))\n",
    "img.shape\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assuming `BinaryCNN` class definition here...\n",
    "\n",
    "net = BinaryCNN()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Freeze backbone parameters\n",
    "for param in net.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=0.001)\n",
    "\n",
    "for epoch in range(1):\n",
    "    for features, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(features)\n",
    "        loss = criterion(outputs, labels.view(-1, 1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "from PIL import Image\n",
    "image = Image.open('test2.jpg')\n",
    "image_tensor = transform(image)\n",
    "image_re = image_tensor.unsqueeze(0)\n",
    "out = net(image_re)\n",
    "prob = torch.sigmoid(out)\n",
    "prob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
